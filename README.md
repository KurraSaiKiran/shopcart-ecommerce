# ğŸ›ï¸ Product Recommendation Engine

A collaborative filtering recommendation system built with Python, FastAPI, and MySQL (AWS RDS). It generates personalized product recommendations using cosine similarity on a user-item rating matrix, and exposes them via a REST API.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ .env                        # DB credentials (never commit this)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ amazon_categories.csv       # Raw category data
â”œâ”€â”€ amazon_products.csv         # Raw product data (~367 MB)
â”œâ”€â”€ to_rds.py                   # Step 1: Load CSVs into RDS
â”œâ”€â”€ load_recommendation_data.py # Step 2: Generate & load dummy user/ratings data
â”œâ”€â”€ recommendation_engine.py    # Step 3: Core ML engine (train + batch generate)
â””â”€â”€ api.py                      # Step 4: FastAPI REST API
```

---

## ğŸ—„ï¸ Database Schema

```
amazon_categories       â† loaded by to_rds.py
amazon_products         â† loaded by to_rds.py
users                   â† generated by load_recommendation_data.py
user_interactions       â† generated by load_recommendation_data.py (implicit feedback)
product_ratings         â† generated by load_recommendation_data.py (explicit feedback)
recommendations         â† generated by recommendation_engine.py (output)
```

---

## âš™ï¸ Setup

### 1. Clone & install dependencies

```bash
git clone <your-repo-url>
cd <project-folder>

python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

### 2. Configure environment variables

Create a `.env` file in the project root:

```env
DB_HOST=your-rds-endpoint.rds.amazonaws.com
DB_PORT=3306
DB_NAME=your_database
DB_USER=your_username
DB_PASSWORD=your_password
```

---

## ğŸš€ Usage

Run the scripts in order:

### Step 1 â€” Load Amazon product data into RDS

```bash
python to_rds.py
```

Reads `amazon_categories.csv` and `amazon_products.csv` and uploads them to MySQL. The products file (~367 MB) is handled in chunks of 50,000 rows to keep memory usage low.

---

### Step 2 â€” Generate dummy user & ratings data

```bash
python load_recommendation_data.py
```

Generates and uploads:
- **5,000 fake users** (name, email, age group, gender, country)
- **100,000 user interactions** (views, clicks, add-to-cart, purchases â€” implicit feedback)
- **30,000 product ratings** (1â€“5 stars â€” explicit feedback, skewed toward higher ratings to mimic real behavior)

All generated data is linked to real product IDs fetched from `amazon_products`.

---

### Step 3 â€” Train & batch generate recommendations

```bash
python recommendation_engine.py
```

This will:
1. Load ratings from the DB
2. Build a user-item matrix
3. Compute cosine similarity between all users
4. Show a sample recommendation for the first user
5. Batch generate and save recommendations for 500 users into the `recommendations` table

---

### Step 4 â€” Start the API

```bash
uvicorn api:app --reload
```

The API loads the model into memory on startup and serves recommendations over HTTP.

---

## ğŸ¤– How the Recommendation Engine Works

The engine uses **user-based collaborative filtering**:

> *"Find users with similar taste to you, then recommend what they liked that you haven't seen yet."*

| Step | What happens |
|------|-------------|
| 1 | Load user-product ratings from DB |
| 2 | Build a **Users Ã— Products** matrix (unfilled = 0) |
| 3 | Compute **cosine similarity** between all user vectors |
| 4 | For a target user, find the **top 20 most similar users** |
| 5 | Collect products those users rated, skip already-rated ones |
| 6 | Compute a **weighted predicted rating** per product (`Î£ similarity Ã— rating / Î£ similarity`) |
| 7 | Return the **top 10** highest-scoring products |

---

## ğŸŒ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check |
| `GET` | `/recommendations/{user_id}` | Get top-N recommendations for a user |

### Example request

```bash
curl http://localhost:8000/recommendations/42
```

### Example response

```json
{
  "user_id": 42,
  "recommendations": [
    {
      "rank": 1,
      "product_id": "B08N5WRWNW",
      "product_name": "Example Product",
      "predicted_rating": 4.712,
      "price": 29.99
    },
    ...
  ]
}
```

---

## ğŸ“¦ File Reference

### `to_rds.py`
Handles the initial one-time data load of raw Amazon CSV files into MySQL RDS.
- Creates the database if it doesn't exist
- Streams the large products CSV in 50K-row chunks to avoid memory issues
- Cleans data: strips whitespace, drops duplicates

### `load_recommendation_data.py`
Generates synthetic user behavior data using the `Faker` library.
- Produces realistic interaction events with weighted probabilities (`view` is most frequent, `purchase` is least)
- Ratings are skewed toward 4â€“5 stars to mimic real-world distributions
- Deduplicates user+product rating pairs to ensure one rating per user per product

### `recommendation_engine.py`
Core ML module. Can run standalone or be imported by the API.
- `build_engine()` â€” creates DB connection
- `load_model(engine)` â€” loads ratings, builds matrix, computes similarity (called once at API startup)
- `get_recommendations(user_id, matrix, similarity_matrix)` â€” returns ranked recommendations for a single user
- `enrich_with_product_details(rec_df, engine)` â€” joins product metadata onto recommendations
- `save_recommendations(user_id, rec_df, engine)` â€” persists results to DB
- `batch_generate(matrix, similarity_matrix, engine)` â€” runs pipeline for all/sampled users

### `api.py`
FastAPI application that exposes the recommendation engine over HTTP.
- Loads the model into memory once at startup for fast inference
- Validates user IDs and returns structured JSON responses

---

## ğŸ”§ Key Configuration

| Variable | Location | Default | Description |
|----------|----------|---------|-------------|
| `NUM_USERS` | `load_recommendation_data.py` | 5,000 | Fake users to generate |
| `NUM_INTERACTIONS` | `load_recommendation_data.py` | 100,000 | Interaction events to generate |
| `NUM_RATINGS` | `load_recommendation_data.py` | 30,000 | Star ratings to generate |
| `TOP_N_SIMILAR_USERS` | `recommendation_engine.py` | 20 | Similar users considered per recommendation |
| `TOP_N_RECOMMENDATIONS` | `recommendation_engine.py` | 10 | Recommendations returned per user |
| `READ_CHUNK_SIZE` | `to_rds.py` | 50,000 | Rows per chunk when reading products CSV |

---

## ğŸ“‹ Requirements

```
pandas
numpy
sqlalchemy
pymysql
scikit-learn
scipy
python-dotenv
faker
fastapi
uvicorn
```

Install all with:

```bash
pip install -r requirements.txt
```

---
